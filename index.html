<!DOCTYPE html>
<html>
<head>

	<link rel="stylesheet" href="styles/main.css">

	<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js" ></script>
	<script src="http://d3js.org/d3.v3.min.js" charset="utf-8"></script>
	<script src="scripts/jquery.csv-0.71.min.js" ></script>

	<!-- Latest compiled and minified Bootstrap CSS -->
	<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.1/css/bootstrap.min.css">

	<!-- Optional Bootstrap theme -->
	<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.1/css/bootstrap-theme.min.css">

	<!-- Latest compiled and minified Bootstrap JavaScript -->
	<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.1/js/bootstrap.min.js"></script>

	<!-- All my custom D3 visualizations -->
	<script src="scripts/main.js" charset="utf-8"></script>
	<script src="scripts/domainDiagram.js" charset="utf-8"></script>
	<script src="scripts/subredditDiagram.js" charset="utf-8"></script>
	<script src="scripts/rankDiagram.js" charset="utf-8"></script>

	<link href='http://fonts.googleapis.com/css?family=Raleway:400,500,700' rel='stylesheet' type='text/css'>

</head>

<body>

	<div class="header">
		<div class="container">
			<h1 style="margin-top: 0; margin-bottom: 3px">Reddit Post Analysis</h1>
			<h3 style="margin-top: 0">A CMSC498O Final Project by <em><a href="https://github.com/JackLot">Jack Lotkowski</a></em> and <em><a href="https://github.com/iLikeSoup">Bradley Neumaier</a></em></h3>
		</div>
	</div>

	<div class="container">

		<div class="headerText"><strong>Introduction.</strong></div> 
		<p style="font-size: 22px;">
			Reddit is a website where a huge community of users submit content and vote (i.e. upvote or downvote) on others submitted content. The premise is simple and the top 25 or so <u>front-page</u> posts change hourly thanks to the active community. There are smaller communities, or <u>subreddits</u>, within the Reddit website where users with similar interests can post/vote on content related only to that category. With our project, we wanted to delve into the posts that make it to the front-page and what types of patterns we could deduce from front-page post data.
		</p>

		<hr /><div class="headerText"><strong>Data Gathering and Wrangling</strong></div>
			<p>
				<a href="https://en.wikipedia.org/wiki/Comma-separated_values">.csv files</a>
			</p>
		<hr /><div class="headerText"><strong>Data Analysis with Python and Pandas</strong></div>
		<p>
			In order to perform data analysis on the data that we scraped from Reddit, we used <a href="http://nbviewer.ipython.org/github/iLikeSoup/Reddit-Post-Analysis-CMSC498O/blob/master/pulls/dataset/CMSC498O%20Final%20Project.ipynb">IPython</a> for our language and environment. For libraries we used pandas and NumPy to perform the bulk of our analysis. 
		</p>
		<p>
			The basic mentality we used to identify patterns was to try to find if some characteristic in the data caused a spike in popularity (whether that popularity was measured in ranking of the posts, scores of the posts, or the number of comments on the posts). To do this, we had to iterate over all the data we scraped, and we had to keep track of various data associated with the category that we were focusing on.
		</p>
		<p>
			Since we stored the data that we scraped from Reddit in a series of .csv files, it was a simple matter to import it into pandas as a DataFrame object. What is a DataFrame object? In order to understand that, you need to understand what makes up a DataFrame.
		</p>

		<h3><strong>NumPy</strong></h3>
		<p>
			NumPy is a 3rd party library in Python that is quite popular. The most important aspect of NumPy is its array. A NumPy array provides a more intuitive way to represent a multi-dimensional array than the standard Python package can do.
		</p>

		<h3><strong>Pandas</strong></h3>
		<p>
			Pandas is also a 3rd party library in Python that enjoys widespread usage. There are two main data structures in Pandas, the Series object and the DataFrame object. You can think of a Series as a 1-dimensional NumPy array (with a few additional features). A DataFrame can be thought of as a dictionary of Series objects. In both Series and DataFrames, you can use custom column and index names, as well as custom index ordering. This last feature is crucial to data analysis.
		</p>

		<h3><strong>What tools were most important?</strong></h3>
		<p>
			A DataFrame is an easy and intuitive way to represent a table. All of the data analysis we performed involved using DataFrames. An especially powerful feature that DataFrames inherits from NumPy is the ability to perform boolean indexing. This allows us to query for posts with specific properties in a succint manner. For example, suppose we wanted to find all posts that had a top 10 ranking. It is a simple matter to find all posts that satisfy that property using boolean indexing.
		</p>
		<p>
			Two other important tools that we used were <a href="https://en.wikipedia.org/wiki/Regular_expression">regular expressions</a> and <a href="https://en.wikipedia.org/wiki/Heap_(data_structure)">heaps</a>. Regular expressions, or regex for short, is used for pattern matching in strings of characters. An example of what we used regex for in our project was to identify what the type of content that a post linked to. E.g., we searched for posts with the strings ".png" or ".jpg" to identify what posts were of images. The heap was used to sort the content of many of our tables. For instance, to identify which subreddits had the most comments, we inserted that the subreddit and its number of comments into a heap in order to sort it in ascending order with the highest number of comments on top.
		</p>

		<h3><strong>IPython Walkthrough</strong></h3>
		<p>Note: to access the IPython notebook click <a href="http://nbviewer.ipython.org/github/iLikeSoup/Reddit-Post-Analysis-CMSC498O/blob/master/pulls/dataset/CMSC498O%20Final%20Project.ipynb">here</a></p>

		<h4><u>Scores</u></h4>
		<img src="images/scoresTable.PNG" alt="Scores Table" width=170 height=220>
		<p>
			We primarily used boolean indexing to calculate the table of scores. We decided to group the indices in the thousands range (0-999, 1000-1999, etc...) in order to present the data in a clear and concise fashion. Since we already had our dataset present, we knew that no post achieved a score of 6000 or higher. Therefore it was simple, to find the posts with a score >= 5000. The other range of scores proved to be more tricky. Initially we thought that we could use conjuction and disjunction within the boolean indexing, but the semantics of the operation did not turn out as we anticipated. We found a work-around by applying another tier of boolean indexing to the data. For example, to find the posts with a score that fit the criteria of 4000 <= score < 5000, we first found all the posts that had a score >= 4000 and stored those posts in another DataFrame. Then we applied the second tier of boolean indexing to that new DataFrame and found all the posts (in the set of posts with score >= 4000) that had a score < 5000.
		</p>

		<h4><u>Rank</u></h4>
		<img src="images/rankTable.PNG" alt="Rank Table" width=325 height=375>
		<p>
			This motivation behind this table was to see how the rank of a post affected the number of comments and the score associated with the post. We used boolean indexing to aggregate the top 100 ranks of the Reddit posts. As our datasets only included the top 100 posts of each day, it was a little unnecessary to use boolean indexing for this. Originally we were only going to find the posts of the top 10 ranks of the Reddit posts, but decided to expand to the entire dataset after seeing the capabilities of <a href="#headerText">D3.js</a>. The simplest way of adapting the code was to code the boolean indexing paramters from rank <= 10 to rank <= 100. We then stored each rank in a list to be used as indices in the table. After that, we iterated through the posts and kept track of the number of comments and score for each.
		</p>

		<h4><u>Domain</u></h4>
		<img src="images/domainTable.PNG" alt="Domain Table" width=1000 height=400>
		<p>
			This table was meant to show the relationship between content type and the domain of the URL from the content that the Reddit post referenced, along with the associated score, rank, and number of comments. We began by storing the data in a dictionary, with the key being the domain name and the values being a list that was composed of the count (the number of times a domain was used in the dataset, so we could calculate averages), the aggregated score, rank, and number of comments, and the content type associated with that particular domain. In order to identify the content type, we had to perform regex on the URL that the Reddit post linked to. The regex we used involved <a href="https://docs.python.org/2/howto/regex.html#non-capturing-and-named-groups">named groups</a>. Basically, we pre-compiled a regex pattern for each of the 4 content types that we were categorizing (images, webpages, Reddit posts, and videos). Each pattern was put in a named group to make it easy to identify which regex produced a match. Then we ran the dataset against each of the patterns, keeping track of when a match occurred and storing the data accordingly.
		</p>
		<p>
			The sorting of this table was tricky as well. We had to utilize both primary and secondary sorting in the heap to order the table appropriately. The way that Python's <a href="https://docs.python.org/2/library/heapq.html">heapq</a> performs this sorting is by passing in a tuple when inserting into the heap. We passed in an integer that mapped to each content type in a dictionary as the first element in the tuple, the number of occurrences associated with the domain as the second element in the tuple, and the domain name as the final element (this final element was needed more so that the appropriate data could be accessed later in the code than for sorting). After that we aggregated the data to line up together in a parallel fashion in various lists, and then aggreated those lists into a dictionary that could be passed in as input to create the DataFrame that represented the finalized product.
		</p>

		<h4><u>Subreddit</u></h4>
		<img src="images/subredditTable.PNG" alt="Subreddit Table" width=580 height=375>
		<p>
			For this table we displayed the subreddits with the highest number of comments. This particular dataset required some of the data to be cleaned within the Python code. The reasons that this wasn't handled in the previous portion of the project was because it was a lot simpler to process this particular cleaning in this iteration with Python than to do it with the Unix tools. Some of the subreddits didn't have /r/ preprended in front of it, so it was a simple matter to add it here. The actual data analytics for this table didn't require anything new from what the previous tables required. It involved iterating through the data, keeping track of subreddits and the associated number of comments, rank, score, and number of occurrences. We used a heap to sort the data based on highest number of comments, and then plugged all the data into a DataFrame.
		</p>

		<h4><u>Length of Title</u></h4>
		<img src="images/titleTable.PNG" alt="Title Length Table" width=700 height=480>
		<p>
			Does the length of a title have an impact on how popular a post on Reddit is? That was what we were wondering when we created this table. It invovled all the standard mechanisms from before (dictionaries, heaps, regex, etc...). The one additional column of data that was required was to calculate the number of words in a title. This is a fairly simple calculation as it turns out. It involves using regex to count the number of spaces in the title, and then adding one to that value (because 2 words will have 1 space in between them, 3 words have 2 spaces in total, etc...).
		</p>

		<h4><u>Length of Username</u></h4>
		<img src="images/usernameTable.PNG" alt="Username Length Table" width=450 height=350>
		<p>
			Similar to the idea from the previous table, does the length of the username have an impact on popular a post on Reddit will be? We used all the tools from before to produce this table. With this table, we had created a table for each of the main categories from the datasets that we scraped from Reddit: scores, rankings, domains and content, subreddit categories, title, and username.
		</p>


		<!-- ------------------------------------------------------------------------ -->

		<hr /><div class="headerText"><strong>D3 Visualizations</strong></div>

		<h2>What constitutes a front page post?</h2>
		<p>
			The posts that make it to the front page were viewed and upvoted more than any of the thousands (even tens and hundreds of thousands) of posts submitted on a particular day. Reddit's ranking algorithm combines a "freshness" weight, along with the number of upvotes to calculate the overall rank of a post.
		</p>
			<br />
				<div class="rtKey" style="float:right; width: 550px;">
					<strong>X Axis</strong>: Post rank, <br /><strong>Y Axis</strong>: Average number of <span id="rtytext">upvotes</span> received
				</div>
			<div class="btn-group" role="group" aria-label="..." style="float: right; margin-right: 20px; position: relative">
				  <button type="button" class="btn btn-default rtbtn active" att="avgUpvotes" ylabel="upvotes" >Average upvotes</button>
				  <button type="button" class="btn btn-default rtbtn" att="avgComments" ylabel="comments" >Average # comments</button>
			</div>

		<div class="rankChart"></div>
		<p class="chartCaption">
			<span class="glyphicon glyphicon-eye-open" style="font-size: 18pt;"></span> As you can see by toggling the bar chart options (above) number of comments received by posts don't seem to follow any pattern unlike the avg number of upvotes received which seem to follow a linearly decreasing pattern (at least for the first 50 or so posts). Additionally, front-page posts receive much less comments than upvotes, meaning users are more apt to upvote a post but not comment on it.
		</p>
		<p>
			Posts that make it to the front-page usually have multiple thousands of upvotes (sometimes as high as 5000) but Reddit's algorithm also factors in a timeliness factor. Density of votes leading up to the present time also means a post may make it to the front page. Of a front page posts, just how many make it to 3, 4 or even 5K upvotes? And do the majority of front-page posts even need that many to make it there in the first place?
		</p>
		<div class="diagram4"></div>

		<hr /><h2>Subreddit Popularity</h2>
		<p>
			Subreddits allow reddit users to group their posts by category and subject matter, but just how popular are some subreddits? Toggle through the popularity measures below to see how the most popular subreddits stack up against each other when it comes to front page posts.
		</p><br />

		<div class="btn-group" role="group" aria-label="..." style="margin-left: 20px;">
		  <button type="button" class="btn btn-default d2btn active" att="numOccurances">Total number of front-page occurances</button>
		  <button type="button" class="btn btn-default d2btn" att="numComments">Total number of comments</button>
		  <button type="button" class="btn btn-default d2btn" att="avgRank">Average Rank</button>
		  <button type="button" class="btn btn-default d2btn" att="avgScore">Average # Upvotes</button>
		</div>
		<div class="diagram2"></div>
		<p class="chartCaption">
			<span class="glyphicon glyphicon-eye-open" style="font-size: 18pt;"></span> As you can see by toggling through the bubble chart options (above), there are certainly subreddits which hit the front page more frequently than others. Of the subreddits that make the front page there are definetly ones that endage the community more (shown by number of comments). When it comes down to average rank and score, subreddits which make the front page tend to have a more-or-less balanced number of upvotes and ranking within the front page.
		</p>

		<hr /><h2>What kinds of posts are Reddit users most interested in?</h2>
		<p>
			Reddit allows users to post content from many different sources: video sites, like Youtube, and image sharing sites, like Imgur, are especially popular. Scroll over the visualization below to see how popular certain types of posts are (the bigger the circle the more popular).
		</p>
		<div class="diagram1"></div>

	</div>
	
</body>

</html>